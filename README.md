# CyberthonCOS
ğŸ¯ Emotion-Aware Emergency Call System for Smarter, Faster Public Safety
â€œIn an emergency, what you feel may be more important than what you say.â€

ğŸš¨ Why It Matters
Traditional emergency helpline systems rely heavily on verbal content to detect urgency. But in real-life crisesâ€”especially in domestic violence, cyber abuse, or public safety threatsâ€”emotions like fear, distress, or aggression often hide behind whispers, panic, or suppressed voices.

âš ï¸ The Problem:
ğŸš« Overwhelming call volumes

ğŸ”‡ Chaotic background noise, whispers, or suppressed voices

ğŸŒ Multilingual inputs (Hindi, Punjabi, English, Hinglish)

ğŸ§â€â™€ï¸ Victims unable to articulate danger directly

ğŸ¢ Delayed triage and missed red flags

ğŸ”¥ The Solution:
An AI-powered system that understands emotions in real timeâ€”even when words failâ€”helping emergency teams respond faster, smarter, and more empathetically.

ğŸ§  What We Built
An LSTM-based Emotion Detection System that processes live audio from emergency calls to:

ğŸ”Š Detect emotions like fear, panic, anger, and distress in real-time

âš¡ Prioritize high-urgency calls

ğŸ›¡ï¸ Enable emotion-aware policing

ğŸ“ Incorporate location awareness, gender, and context

ğŸ” Improve continuously through real-world feedback

ğŸ” Data & Preprocessing
ğŸ™ï¸ Audio Dataset
We used the TESS Toronto Emotional Speech Dataset with over 800 emotion-tagged audio samples. Every clip features the same sentence, spoken with different emotionsâ€”making the text content irrelevant.

âœ… This enables multilingual compatibility even when trained on English audio, because the model learns tone, not meaning.

ğŸ”§ Preprocessing Steps
Format conversion to .wav

Volume normalization

Noise reduction via FFT â†’ High Pass Filter â†’ Inverse FFT

Retention of short silences to preserve breathing/stress cues

Removal of long silences and distortions

ğŸ¤– Why LSTM?
LSTM (Long Short-Term Memory) models are ideal for sequential audio processing. They retain temporal context, allowing us to:

ğŸšï¸ Break audio into small time segments (to isolate speakers)

ğŸ—£ï¸ Handle multi-speaker scenarios (e.g. abuser yelling, victim whispering)

ğŸ¯ Predict emotional tone per segment and aggregate insights

âš™ï¸ Key Features
1. ğŸš¦ Real-Time Emergency Call Prioritization
Detect stress, panic, or fear even if the caller is whispering or crying.

Automatically flag emotionally intense calls

Boost response time for victims in critical danger

Reduce manual analysis load for dispatchers

2. ğŸ“² Mobile App Integration
Integrate with SOS apps or panic buttons.

Analyze user tone in distress

Trigger instant alerts to law enforcement or mental health services

3. ğŸ§© Police Control Room Integration
Designed for plug-and-play API integration into existing 100/112 helpline systems.

Add emotion-aware intelligence to current infrastructure

Enable automated triaging & dispatch recommendations

4. ğŸ§  Continuous Learning Loop
Get smarter with every call.

Model improves with new emergency data

Adapts to regional accents, urban noise, and multilingual inputs

5. ğŸ›°ï¸ Multi-Modal Fusion (Coming Soon)
Combine:

Audio-based emotion detection

Text transcripts

Background noise classification

Location-based crime history
To enable smarter dispatch decisions

ğŸŒ Use Cases
ğŸš“ Police Emergency Units

ğŸ§• Women Safety Cells

ğŸ§  Mental Health Helplines

ğŸ”¥ Fire & Disaster Response

ğŸš‘ Ambulance Services

ğŸŒŸ Why Chandigarh (Pilot City)?
As a modern Indian city facing rising domestic, cyber, and public safety threats, Chandigarh is a perfect testbed for an AI-first policing model. Emotion-aware triage can revolutionize public trust and response times.

ğŸ“ˆ Impact
ğŸ• Faster Police Dispatch

ğŸ” Better Urgency Detection

ğŸ’¬ Support for Silent or Suppressed Victims

ğŸ“ Smarter Call Routing & Prioritization

ğŸ›¡ï¸ A New Standard for Tech-Enabled Public Safety in India

